# GitHub Issues

* Issue 5: Literatuur Scan: LSD-SLAM
  * In samenwerking met Isa Isaku gemaakt. Voor dit issue is er gekeken naar verschillende soorten papers over LSD-SLAM met verschillende configuraties. Aan de hand van de papers begonnen wij globaal alle papers te lezen en selecteren welke papers potentiële kandidaten zijn voor het project. Alle gevonden papers zijn terug te vinden in de map [LSD-SLAM papers](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/LSD-SLAM%20Papers). De volgende papers bleken de meest relevante informatie te bevatten. [Jacob Engel - 2014](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Documentatie:Papers/LSD-SLAM%20Papers/engel%202014%20lsd-slam%20large%20scale%20direct%20monocular%20slam.pdf) & [Jacob Engel - 2015](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Documentatie:Papers/LSD-SLAM%20Papers/engel%202015%20Large-Scale%20Direct%20SLAM%20with%20Stereo%20Cameras.pdf). Deze zijn gekozen om een samenvatting van het algoritme te maken. 

* Issue 23: Werking LSD-SLAM-algoritme begrijpen
  * In samenwerking met Isa Isaku en Jeroen Vuurens gemaakt. Na issue 5 is er geprobeerd om de werking van het LSD-SLAM-algoritme de begrijpen en in zicht te brengen. Dit is gedaan door het maken van een korte samenvatting van alle belangrijke papers. De samenvatting is terug te vinden als het volgende [bestand](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%204%20-%20LSD-SLAM.pdf).

* Issue 28: ORB-SLAM 2 paper bestuderen
  *	In samenwerking met Kevin van Veen. Voor dit issue is er gekeken naar papers over ORB-SLAM2. Deze zijn in de map “ORB-SLAM2” terug te vinden. Om de werking ervan te vereenvoudigen is er tevens een samenvatting gemaakt om het ORB-SLAM2 algoritme uit te leggen. Deze samenvatting is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2028%20-%20ORB-SLAM2.pdf).

* Issue 34: Camera kalibratie
  * In samenwerking met Chris Ros, Daniello Doran en Jeffrey van Hoven gemaakt. Tijdens de tweede sprint zijn er door ons camera beelden gemaakt van de slinger. Dit werd gedaan omdat wij het ORB-SLAM2 algoritme wilden uitproberen op een eigen dataset. Voordat deze camera’s de juiste opnames konden maken moest er door middel van een kalibratietool van ROS (Robot Operating System) de camera’s gekalibreerd worden. De camera beelden zijn geschoten door middel van het monteren van twee webcams op een trolley en dan een video opname te maken terwijl er door de gang werd gereden. Alle documentatie hiervan is in de map [camera kalibratie](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Camera%20Kalibratie) terug te vinden (met de exceptie van de daadwerkelijke opnames, aangezien deze de maximale uploadt grootte van GitHub overschrijden).
  
* Issue 37: REMODE-onderzoek
  * In samenwerking met Said De Lanooi gemaakt. Om de werking van REMODE te begrijpen is er gekeken naar het volgende paper in de map “REMODE”. Vervolgens is er een beknopte samenvatting gemaakt om REMODE eenvoudig uit te leggen. Dit document is terug te vinden in het volgende [bestand](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2037%20-%20REMODE%20(REgularized%20MOnocular%20Depth%20Estimation)%20Onderzoek.pdf).

* Issue 51: ORB2 extracten points naar .csv file 
  *	In samenwerking met Daniello Doran is dit issue opgeleverd. Er is samen gekeken naar een reeds bestaande methode die het mogelijk maakte om een map te kunnen extraheren van de KITTI-dataset in ORB-SLAM2. Deze methode is herschreven om de map points (x, y, z-coördinaten) te extracten naar een .csv bestand. De code voor extraheren van de map points is te vinden in [deze](https://github.com/urbinn/orb2/commit/f8dd886e4611bca74365a746bf530b5b61fef7a5) commit.

* Issue 55: Object detection papers lezen
  * Alle geroepsleden moesten de Object Detection papers lezen die wij voor de close reading sessie hadden gekozen. De twee papers zijn hier te vinden in de map [Real Time Object Detection](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/Real%20Time%20Object%20Detection).

* Issue 58: Beschrijven datastructuur MapPoint in ORB-SLAM2
  * In samenwerking met Daniello Doran gemaakt. Er is een JavaDoc documentatie stijl aangehouden bij het documenteren van de methodes in de MapPoint.cc klasse. Er is gekeken naar de werking van alle methodes binnen de klasse en daaraan documentatie opgesteld. Ook zijn de eventuele parameters die aanwezig waren en het resultaat wat de methode oplevert gedocumenteerd. De commit voor dit issue is [hier](https://github.com/urbinn/orb2/commit/e33bd1594242c5b84aafdd07ab8dff14047c9a86) terug te vinden.

* Issue 60: Beschrijven structuur KeyFrameDatabase in ORB2
  * In samenwerking met Daniello Doran gemaakt. Er is een JavaDoc documentatie stijl aangehouden bij het documenteren van de methodes in de KeyFrameDatabase.cc klasse. Er is gekeken naar de werking van alle methodes binnen de klasse en daaraan documentatie opgesteld. Ook zijn de eventuele parameters die aanwezig waren en het resultaat wat de methode oplevert gedocumenteerd. De documentatie is terug te vinden in [deze](https://github.com/urbinn/orb2/commit/1d5c19b886e02578a431508bff8ca016b49a15f7) commit.

* Issue 72: Resultaten ORB2 bin exporteren
  * In samenwerking met Daniello Doran gemaakt. Door in ORB_SLAM2 een sequentie aan foto’s in te laden en het algoritme erop te laten werken, wordt er door ORB een weergave getoond van de gevonden ORBS in de sequentie aan foto’s. Hiervan moest er een .bin bestand geëxporteerd worden wanneer het algoritme klaar was met de bevindingen. Het maken van de export vereiste dat de broncode aangepast moest worden, zodat er na de bevindingen van de orbs, de .bin file geëxporteerd zou worden in een aangegeven map. De gemaakte code is terug te vinden in [deze](https://github.com/urbinn/orb2/commit/48eddc4ac138f6492faee733946ab7e1768cda9f) commit.
  
* Issue 74: Yolo run KITTI evalueren tegen ground truth object 2D task
  * In samenwerking met Chris Ros en Kevin van Veen gemaakt. De Yolo run van de KITTI dataset moest geëvalueerd worden tegen de ground truth van de KITTI [object 2D task](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d) van de KITTI website. Zelf heb ik YOLO geëvalueerd aan de hand van de KITTI dataset. Deze dataset beschikt over 2D objecten met een eigen groundtruth. De evaluatie is uitgevoerd aan de hand van een script. De [uitkomsten](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2074%20-%20Yolo%20Evaluation) van deze evaluatie bleken goed te zijn.

* Issue 82: Yolo training data verzamelen
  * In samenwerking met Kevin van Veen gemaakt. Om Yolo te trainen moesten er zo veel mogelijke (Europese) datasets worden verzameld. Van de datasets moesten verschillende objecten aanwezig zijn (borden, stoplichten, verkeerstekens etc). Bij deze datasets moest er ook een eventuele Ground Truth aanwezig zijn van de data die al gelabeld was. Alle datasets met labels moesten uiteindelijk ook op de server worden geüpload om er gebruik van te maken in de komende issues. De dataset zijn terug te vinden op de server onder "/data/urbinn/datasets".
  
* Issue 86: Ground truth nieuwe trainingsdata labelen
  * In samenwerking met Kevin van Veen en Chris Ros gemaakt. Voor het labelen van de trainingsdata van de KITTI dataset was het nodig om een tool te vinden die het mogelijk maakt om zelf klassen te labelen. Dit wordt gedaan om YOLO te trainen op meerdere klassen. De KITTI dataset had namelijk vier klassen die gebruikt werden, dit moeten voor onze situatie natuurlijk veel meer zijn. De tool die we gevonden hebben is de [BBox-Label-Tool](https://github.com/puzzledqs/BBox-Label-Tool) van puzzledqs. Hierin konden alle foto's van de dataset ingeladen worden om te labelen. <br /> <br />Er waren echter wel een aantal problemen aanwezig, zo was het programma niet bepaald gebruiksvriendelijk met het selecteren van klassen om te labelen. Dit hebben wij opgelost door middel van het forken van de tool en het aanpassen van de source code. Deze [fork](https://github.com/urbinn/BBox-Label-Tool) is terug te vinden in de urbinn repository met de betreffende wijzigen bovenaan vermeldt in de README. Ook moesten de dataset foto's van een bepaald formaat zijn, namelijk JPG's. Aangezien de foto's in PNG formaat waren, moesten deze eerst omgezet worden om überhaupt de foto's in te kunnen laden. Dit is gedaan middels een python script die door Jeroen Vuurens is geschreven op Jupyterhub onder "/data/urbinn/notebooks/yolo_gt_eval/convertPngToJpg.ipynb". Bovendien was het nodig om de coördinaten, die de tool exporteerd, om te zetten naar een formaat waarmee getraind kon worden. Dit hebben we opgelost door het volgende [script](https://github.com/Guanghan/darknet/blob/master/scripts/convert.py) te gebruiken. <br /> <br />
  Tot slot moesten alle klassen van het volgende [excel bestand](https://docs.google.com/spreadsheets/d/1B9jabEJgo_CQKnJTPorHLHq5gcTB_onDxKndBN_Dj7I/edit#gid=0) handmatig toegevoegd worden in het label programma om zo meerdere klassen te kunnen trainen. Na alle bovenstaande problemen opgelost te hebben kon er eindelijk begonnen worden om 7500 afbeeldingen handmatig te labelen met de juiste klassen. Een aantal van deze handmatig gelabelde afbeelding zijn [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Issues/Issue%2086%20-%20Ground%20truth%20nieuwe%20trainingsdata%20labelen) terug te vinden.

* Issue 87: Paper zoeken voor close reading sessie
  * Voor de volgende close reading sessie moest er een paper gevonden worden over hoe er een semantische map geëvalueerd kan worden. Hiervoor waren er twee potentiële papers gevonden. Deze papers zijn terug te vinden onder de map [Semantic Map Evaluation Papers](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/Semantic%20Map%20Evaluation%20Papers).

* Issue 89: Import XML data (pointcloud) ORB-SLAM2
  * In samenwerking met Daniello Doran. De pointcloud van de geëxporteerde resultaten van ORB-SLAM2 moesten ook weer geïmporteerd kunnen worden als XML data in ORB-SLAM2. Hiervoor moest de XML structuur van de export nagemaakt worden in code om deze in het systeem weer in te lezen. De gemaakte code voor deze issue is [hier](https://github.com/urbinn/orb2/commits/Save/Load) terug te vinden.
  
* Issue 90: Stereocamera beelden Slinger
  * In samenwerking met Chris Ros gemaakt. Bij het verkrijgen van de nieuwe ZED-camera die stereo beelden kon schieten, hebben Chris en ik een nieuwe opnames gemaakt van de Slinger. Dit hebben we gedaan om de milestone te gaan behalen door middel van het herkennen van objecten in de Slinger. De beelden zijn geüpload naar de server om gebruikt te worden bij de andere issues.

* Issue 92: Kalibratie camera
  * In samenwerking met Chris Ros gemaakt. Voordat de nieuwe ZED-camera gebruikt kon worden moest deze gekalibreerd worden. Dit is gedaan door middel van het opzoeken op de website van de camera en het invoeren van het serienummer van de camera. Hiermee kon de camera gekalibreerd zoals de fabrieksinstellingen gekalibreerd worden. Het kalibratiebestand is te downloaden via [deze](https://www.stereolabs.com/developers/calib/?SN=000015040) link.
  
* Issue 93: Trainen tiny YOLO maandag nacht
  * In samenwerking met Kevin van Veen, Chris Ros en Jeroen Vuurens gemaakt. Het trainen van YOLO vereist veel werk vooraf. Zo moet er bijvoorbeeld meerdere klassen worden toegevoegd. Kevin en ik hebben gekeken naar het runnen van tiny-yolo op de server, dit ging helaas niet wegens problemen met de GPU's op de server in Leiden. Hierna kregen wij problemen met het runnen via Darknet er werden CUDA GPU errors gegeven, dit werd uiteindelijk opgelost door het updaten van de CUDA drivers op de server. Hierna is het trainen van yolo in de nacht goed gegaan, het duurde ongeveer twee uur om tot 10000 batches te komen, daarna is het aantal batches verhoogd en verder geleerd vanaf 10000. Nadat de weights tot 70000 was weggeschreven (dit zijn ongeveer 18 miljoen afbeeldingen) lijkt de gemiddelde percentage gelabelde objecten dat herkend wordt 50% te zijn. 
  
* Issue 98: YOLO config file beschrijven
  * In samenwerking met Kevin van Veen gemaakt. Om een duidelijker beeld te krijgen voor de configuratie van tiny-yolo die gebruikt wordt bij het trainen, is er besloten om de configuratie zo veel mogelijk te beschrijven. Dit excel bestand is als pdf [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2098%20-%20YOLO%20config%20file%20beschrijven%20.pdf) terug te vinden. 
  
* Issue 115: Plan opnames Delft: Uitzoeken GPS
  * In samenwerking met Kevin van Veen gemaakt. Het idee was om per afbeelding in opnames van Delft ook GPS data op te nemen. Hoe we dit wilden doen moest uitgezocht worden. Samen met Kevin gingen we opzoek naar GPS-tracking applicatie die beschikbaar waren voor smartphones. Daarmee kwamen we tot de conclusie dat er een applicatie genaamd [GPS Logger App](https://play.google.com/store/apps/details?id=eu.basicairdata.graziano.gpslogger&hl=nl) vele voordelen biedt voor dit probleem. Het kan namelijk onder andere real time GPS coördinaten loggen, het bevat de timestamps en het kan de output exporteren naar KML, GPX en TXT formaat. Na nader overleg kwamen we tot de conclusie dat de timestamps van de GPS Logger misschien niet goed gematched konden wordne aan de opnames, dus onbetrouwbare resultaten zouden opleveren. Om dit probleem op te lossen vonden we  een applicatie die op de computer gerunned kon worden genaamd [HoudahGeo](https://www.houdah.com/houdahGeo/). Deze applicatie heeft wel een betaalde licentie nodig van $34,-. Uiteindelijk is er na lang overleg besloten om geen gebruik te maken van GPS als evaluatie voor eventuele latere correctie.
  
* Issue 121: Semantic mapping
  * In samenwerking met Kevin van Veen gemaakt. De bedoeling is om uiteindelijk YOLO en URB met elkaar te koppelen. Het doel van dit issue was om de resultaten van de posities van de herkende objecten van YOLO te tekenen in de trajectory die uit URB komt. Dit was gedaan door middel van de id's van de frames, waar de objecten in zijn herkend, te pakken en deze met de keyframes van de trajectory te matchen. Hierna kan de trajectory aangevuld worden met de objecten die met die met de betreffende frames corresponderen.
  
* Issue 129: Labelen evaluatie set Kitti
  * In samenwerking met Kevin van Veen gemaakt. Voor het evalueren van de labels met de KITTI set moesten er 200 foto's gelabeld worden die gebruikt zouden worden als evaluatie. De foto's 7300 - 7390 zijn door mij gelabeld en de foto's 7391 - 7480 waren door Kevin gelabeld. Alle labels zijn [hierin](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Issues/Issue%20129%20-%20Labelen%20evaluatie%20set%20Kitti) terug te vinden. Label 007300.txt is representatief voor alle andere labels. 
  
* Issue 131: URB plot trajectory
  * In samenwerking met Kevin van Veen gemaakt. In jupyterhub is de notebook plot_trajectory aangemaakt, deze is terug te vinden onder /notebooks/urbinn/urb/trajectory/plot_trajectory.ipynb. Er is een stuk code geschreven om te kijken of we met 3 keyframes een trajectory kunnen tekenen met behulp van opencv. Wanneer wij de grafiek wilden plotten werd er een error gegeven. Dit moest worden opgelost door libgtk2.0-dev en pkg-config op de server te installeren. Tevens moet cmake re-runned worden of de configure script in function cvShowImage. Na het ontdekt te hebben dat wij de rotation niet in acht hadden genomen, hebben wij de Python notebooks zo veranderd dat er bij het tekenen van de trajectory hier wel rekening mee werd gehouden. Het resultaat in de vorm van een 2d-grafiek (van bovenaf) van de notebook is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%20131%20-%20Trajectory.png) als afbeelding terug te vinden.
  
* Issue 135: Analyseren van Sequence 01 van de KITTI dataset
  * In samenwerking met Kevin van Veen gemaakt. De sequence 01 van KITTI moest geanalyseerd worden. Aangezien er problemen waren met het tekenen van de trajectory met behulp van URB, grote afwijkingen vergeleken de ground truth, moest er gekeken worden bij welke frames van de sequentie het fout gaat. Door dit in kaart te brengen en bij te houden kan er geëxperimenteerd worden met de configuratie van URB, bijvoorbeeld de tresholds, Local Bundle Adjustment en het filteren van ruis. Het excel bestand met de resultaten van de gebruikte configuraties zijn [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%20135%20-%20Configuratie.xlsx) te vinden. Dit bestand is niet als PDF omgezet door de grootte van het bestand. Met behulp van deze analyse wilden wij kijken of de problemen op te lossen waren door de configuraties van URB aan te passen, mocht dit niet het geval zijn dan moeten wij Local Bundle Adjustment erop toepassen om te controleren of de trajectory beter wordt getekend. 
  
* Issue 152: Paper 1. Introduction
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg en Isa Isaku gemaakt. De introductie van het paper bevat een onderdeel over het gebruik van autonoom rijdende auto's en de trend in het onderzoek ervan. Tevens is er een klein stuk geschreven over het doel van Urbinn voor autonoom rijdenden auto's. De gehele introductie is eerst door Viradj en ik geschreven en is door de rest zo nodig aangepast om het voor het paper passend te maken. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden.
  
* Issue 153: Paper 2. Related Work
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het paper van Urbinn was het nodig om een korte beschrijving te geven wat betreft het SLAM algoritme, de korte beschrijving over de verschillende SLAM algoritmes welke onderzocht waren voor het project en een korte beschrijving geven over het gebied van object detectie. Bovendien moest er nog een onderdeel geschreven worden over de related work op het gebied van semantic mapping. Zelf heb ik de SLAM algoritmes ORB-SLAM2, SVO-SLAM en LSD-SLAM en het deel over object detectie wat betreft YOLO geschreven. De rest hebben mij geholpen met het herschrijven van deze alinea's. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden. 
  
* Issue 154: Paper 3. Design
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het onderdeel "Design" van het paper moest er een beschrijving komen die aangaf wat onze aanpak voor het project was. Hiervoor moesten we een beschrijving geven op het gebied van landmark detection aan de hand van vertical edges. Hier moest ook onderzocht worden of er al nader onderzoek op dit gebied was gedaan. Tot slot moest er een beschrijving komen voor de locatiebepaling van objecten door combinatie YOLO en URB. Dit onderdeel is voor het grootste gedeelte door Kevin en mij gemaakt. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden. 
  
* Issue 155: Paper 4. Experiment
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het onderdeel "Experiment" van het paper moest er beschreven worden wat voor een experiment wij hadden gedaan om ons algoritme te testen. Dit was gedaan door middel van de KITTI-dataset. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden.
  
* Issue 157: Paper 5. Results
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het onderdeel "Results" van het paper moest er beschreven worden wat voor de resultaten van het experiment waren. Deze resultaten gingen wij vergelijken aan de hand van de ground truth van de KITTI-dataset. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden.

* Issue 158: Paper 6. Discussion
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het onderdeel "Discussion" gaan wij discussieren over de verbeteringen van ons algoritme en over de toekomstige stappen die ondernomen kunnen worden om dit te verbeteren. De discussie is voor het grootste gedeelte door Kevin, Viradj en ik gemaakt. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden.
  
* Issue 159: Paper 7. Conclusion
  * In samenwerking met Viradj Ramlochwan Tewarie, Bob van Elburg, Kevin van Veen en Isa Isaku gemaakt. Voor het onderdeel "Conclusion" beschrijven wij de conclusie van ons onderzoek. De conclusie is voornamelijk door Kevin, Viradj en ik gemaakt. Het paper is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Paper/landmark-filtering-techniques-for-semantic-mapping.pdf) te vinden.
  
* Presentatie & notulen week 1 en 2 (sprint 1)
  * Notulen en presentatie in samenwerking met Chris Ros gemaakt. Chris heeft zich voornamelijk beziggehouden met het opzetten van de presentaties. Bovendien vulde ik, indien het nodig was, de presentatie aan met extra informatie. Ik hield mij iedere dag bezig met het notuleren van de belangrijkste besproken dingen van die dag. De notulen van de eerste sprint zijn te vinden in de map [notulen](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Notulen) en de presentaties zijn in de map [presentaties](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Presentaties) terug te vinden.

* Presentatie & notulen week 11 en 12 (sprint 6)
  * Notulen en presentatie in samenwerking met Kevin van Veen gemaakt. Samen met Kevin hebben wij de presentaties in elkaar gezet en tevens ook de blog geüpdate. Zelf heb ik de notulen en de sprint retrospective bijgehouden. De notulen van de zesde sprint zijn te vinden in de map [notulen](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Notulen) en de presentaties zijn in de map [presentaties](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Presentaties) terug te vinden.
