# GitHub Issues

* Issue 5: Literatuur Scan: LSD-SLAM
  * In samenwerking met Isa Isaku gemaakt. Voor dit issue is er gekeken naar verschillende soorten papers over LSD-SLAM met verschillende configuraties. Aan de hand van de papers begonnen wij globaal alle papers te lezen en selecteren welke papers potentiële kandidaten zijn voor het project. Alle gevonden papers zijn terug te vinden in de map [LSD-SLAM papers](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/LSD-SLAM%20Papers). De volgende papers bleken de meest relevante informatie te bevatten. [Jacob Engel - 2014](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Documentatie:Papers/LSD-SLAM%20Papers/engel%202014%20lsd-slam%20large%20scale%20direct%20monocular%20slam.pdf) & [Jacob Engel - 2015](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Documentatie:Papers/LSD-SLAM%20Papers/engel%202015%20Large-Scale%20Direct%20SLAM%20with%20Stereo%20Cameras.pdf). Deze zijn gekozen om een samenvatting van het algoritme te maken. 

* Issue 23: Werking LSD-SLAM-algoritme begrijpen
  * In samenwerking met Isa Isaku en Jeroen Vuurens gemaakt. Na issue 5 is er geprobeerd om de werking van het LSD-SLAM-algoritme de begrijpen en in zicht te brengen. Dit is gedaan door het maken van een korte samenvatting van alle belangrijke papers. De samenvatting is terug te vinden als het volgende [bestand](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%204%20-%20LSD-SLAM.pdf).

* Issue 28: ORB-SLAM 2 paper bestuderen
  *	In samenwerking met Kevin van Veen. Voor dit issue is er gekeken naar papers over ORB-SLAM2. Deze zijn in de map “ORB-SLAM2” terug te vinden. Om de werking ervan te vereenvoudigen is er tevens een samenvatting gemaakt om het ORB-SLAM2 algoritme uit te leggen. Deze samenvatting is [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2028%20-%20ORB-SLAM2.pdf).

* Issue 34: Camera kalibratie
  * In samenwerking met Chris Ros, Daniello Doran en Jeffrey van Hoven gemaakt. Tijdens de tweede sprint zijn er door ons camera beelden gemaakt van de slinger. Dit werd gedaan omdat wij het ORB-SLAM2 algoritme wilden uitproberen op een eigen dataset. Voordat deze camera’s de juiste opnames konden maken moest er door middel van een kalibratietool van ROS (Robot Operating System) de camera’s gekalibreerd worden. De camera beelden zijn geschoten door middel van het monteren van twee webcams op een trolley en dan een video opname te maken terwijl er door de gang werd gereden. Alle documentatie hiervan is in de map [camera kalibratie](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Camera%20Kalibratie) terug te vinden (met de exceptie van de daadwerkelijke opnames, aangezien deze de maximale uploadt grootte van GitHub overschrijden).
  
* Issue 37: REMODE-onderzoek
  * In samenwerking met Said De Lanooi gemaakt. Om de werking van REMODE te begrijpen is er gekeken naar het volgende paper in de map “REMODE”. Vervolgens is er een beknopte samenvatting gemaakt om REMODE eenvoudig uit te leggen. Dit document is terug te vinden in het volgende [bestand](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/blob/master/Issues/Issue%2037%20-%20REMODE%20(REgularized%20MOnocular%20Depth%20Estimation)%20Onderzoek.pdf).

* Issue 51: ORB2 extracten points naar .csv file 
  *	In samenwerking met Daniello Doran is dit issue opgeleverd. Er is samen gekeken naar een reeds bestaande methode die het mogelijk maakte om een map te kunnen extraheren van de KITTI-dataset in ORB-SLAM2. Deze methode is herschreven om de map points (x, y, z-coördinaten) te extracten naar een .csv bestand. De code voor extraheren van de map points is te vinden in [deze](https://github.com/urbinn/orb2/commit/f8dd886e4611bca74365a746bf530b5b61fef7a5) commit.

* Issue 55: Object detection papers lezen
  * Alle geroepsleden moesten de Object Detection papers lezen die wij voor de close reading sessie hadden gekozen. De twee papers zijn hier te vinden in de map [Real Time Object Detection](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/Real%20Time%20Object%20Detection).

* Issue 58: Beschrijven datastructuur MapPoint in ORB-SLAM2
  * In samenwerking met Daniello Doran gemaakt. Er is een JavaDoc documentatie stijl aangehouden bij het documenteren van de methodes in de MapPoint.cc klasse. Er is gekeken naar de werking van alle methodes binnen de klasse en daaraan documentatie opgesteld. Ook zijn de eventuele parameters die aanwezig waren en het resultaat wat de methode oplevert gedocumenteerd. De commit voor dit issue is [hier](https://github.com/urbinn/orb2/commit/e33bd1594242c5b84aafdd07ab8dff14047c9a86) terug te vinden.

* Issue 60: Beschrijven structuur KeyFrameDatabase in ORB2
  * In samenwerking met Daniello Doran gemaakt. Er is een JavaDoc documentatie stijl aangehouden bij het documenteren van de methodes in de KeyFrameDatabase.cc klasse. Er is gekeken naar de werking van alle methodes binnen de klasse en daaraan documentatie opgesteld. Ook zijn de eventuele parameters die aanwezig waren en het resultaat wat de methode oplevert gedocumenteerd. De documentatie is terug te vinden in [deze](https://github.com/urbinn/orb2/commit/1d5c19b886e02578a431508bff8ca016b49a15f7) commit.

* Issue 72: Resultaten ORB2 bin exporteren
  * In samenwerking met Daniello Doran gemaakt. Door in ORB_SLAM2 een sequentie aan foto’s in te laden en het algoritme erop te laten werken, wordt er door ORB een weergave getoond van de gevonden ORBS in de sequentie aan foto’s. Hiervan moest er een .bin bestand geëxporteerd worden wanneer het algoritme klaar was met de bevindingen. Het maken van de export vereiste dat de broncode aangepast moest worden, zodat er na de bevindingen van de orbs, de .bin file geëxporteerd zou worden in een aangegeven map. De gemaakte code is terug te vinden in [deze](https://github.com/urbinn/orb2/commit/48eddc4ac138f6492faee733946ab7e1768cda9f) commit.

* Issue 82: Yolo training data verzamelen
  * In samenwerking met Kevin van Veen gemaakt. Om Yolo te trainen moesten er zo veel mogelijke (Europese) datasets worden verzameld. Van de datasets moesten verschillende objecten aanwezig zijn (borden, stoplichten, verkeerstekens etc). Bij deze datasets moest er ook een eventuele Ground Truth aanwezig zijn van de data die al gelabeld was. Alle datasets met labels moesten uiteindelijk ook op de server worden geüpload om er gebruik van te maken in de komende issues. De dataset zijn terug te vinden op de server onder "/data/urbinn/datasets".
  
* Issue 86: Ground truth nieuwe trainingsdata labelen
  * In samenwerking met Kevin van Veen en Chris Ros gemaakt. Voor het labelen van de trainingsdata van de KITTI dataset was het nodig om een tool te vinden die het mogelijk maakt om zelf klassen te labelen. Dit wordt gedaan om YOLO te trainen op meerdere klassen. De KITTI dataset had namelijk vier klassen die gebruikt werden, dit moeten voor onze situatie natuurlijk veel meer zijn. De tool die we gevonden hebben is de [BBox-Label-Tool](https://github.com/puzzledqs/BBox-Label-Tool) van puzzledqs. Hierin konden alle foto's van de dataset ingeladen worden om te labelen. <br /> <br />Er waren echter wel een aantal problemen aanwezig, zo was het programma niet bepaald gebruiksvriendelijk met het selecteren van klassen om te labelen. Dit hebben wij opgelost door middel van het forken van de tool en het aanpassen van de source code. Deze [fork](https://github.com/urbinn/BBox-Label-Tool) is terug te vinden in de urbinn repository met de betreffende wijzigen bovenaan vermeldt in de README. Ook moesten de dataset foto's van een bepaald formaat zijn, namelijk JPG's. Aangezien de foto's in PNG formaat waren, moesten deze eerst omgezet worden om überhaupt de foto's in te kunnen laden. Dit is gedaan middels een python script die door Jeroen Vuurens is geschreven op Jupyterhub onder "/data/urbinn/notebooks/yolo_gt_eval/convertPngToJpg.ipynb". Bovendien was het nodig om de coördinaten, die de tool exporteerd, om te zetten naar een formaat waarmee getraind kon worden. Dit hebben we opgelost door het volgende [script](https://github.com/Guanghan/darknet/blob/master/scripts/convert.py) te gebruiken. <br /> <br />
  Tot slot moesten alle klassen van het volgende [excel bestand](https://docs.google.com/spreadsheets/d/1B9jabEJgo_CQKnJTPorHLHq5gcTB_onDxKndBN_Dj7I/edit#gid=0) handmatig toegevoegd worden in het label programma om zo meerdere klassen te kunnen trainen. Na alle bovenstaande problemen opgelost te hebben kon er eindelijk begonnen worden om 7500 afbeeldingen handmatig te labelen met de juiste klassen. Een aantal van deze handmatig gelabelde afbeelding zijn [hier](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Issues/Issue%2086%20-%20Ground%20truth%20nieuwe%20trainingsdata%20labelen) terug te vinden.

* Issue 87: Paper zoeken voor close reading sessie
  * Voor de volgende close reading sessie moest er een paper gevonden worden over hoe er een semantische map geëvalueerd kan worden. Hiervoor waren er twee potentiële papers gevonden. Deze papers zijn terug te vinden onder de map [Semantic Map Evaluation Papers](https://github.com/NektariosEvangelou/KB-74-Urbinn-Portfolio/tree/master/Documentatie:Papers/Semantic%20Map%20Evaluation%20Papers).

* Issue 90: Stereocamera beelden Slinger
  * In samenwerking met Chris Ros gemaakt. Bij het verkrijgen van de nieuwe ZED-camera die stereo beelden kon schieten, hebben Chris en ik een nieuwe opnames gemaakt van de Slinger. Dit hebben we gedaan om de milestone te gaan behalen door middel van het herkennen van objecten in de Slinger. De beelden zijn geüpload naar de server om gebruikt te worden bij de andere issues.

* Issue 92: Kalibratie camera
  * In samenwerking met Chris Ros gemaakt. Voordat de nieuwe ZED-camera gebruikt kon worden moest deze gekalibreerd worden. Dit is gedaan door middel van het opzoeken op de website van de camera en het invoeren van het serienummer van de camera. Hiermee kon de camera gekalibreerd zoals de fabrieksinstellingen gekalibreerd worden. Het kalibratiebestand is te downloaden via [deze](https://www.stereolabs.com/developers/calib/?SN=000015040) link.
  
* Issue 93: Trainen tiny YOLO maandag nacht
  * In samenwerking met Kevin van Veen gemaakt. Het trainen van YOLO vereist veel werk vooraf. Zo moet er bijvoorbeeld meerdere klassen worden toegevoegd **TODO add description**

* Presentatie & notulen week 1 en 2 (sprint 1)
  * Notulen en presentatie in samenwerking met Chris Ros gemaakt. Chris heeft zich voornamelijk beziggehouden met het opzetten van de presentaties. Bovendien vulde ik, indien het nodig was, de presentatie aan met extra informatie. Ik hield mij iedere dag bezig met het notuleren van de belangrijkste besproken dingen van die dag. 

